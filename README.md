# ğŸš€ Cloud Computing Demo - IngenierÃ­a del Software II  

Este repositorio contiene instrucciones detalladas y recursos utilizados durante la clase prÃ¡ctica de Cloud Computing. AquÃ­ aprenderÃ¡s desde los primeros pasos bÃ¡sicos hasta prÃ¡cticas avanzadas con infraestructura como cÃ³digo y pipelines CI/CD usando AWS y GCP.

**Diapos**: [Cloud Computing Slides](https://www.figma.com/deck/yJpxpjW6aJOpFBCW7TE1xW/ISW2---Cloud-Computing?node-id=1-660&t=ep8V4cm1Nw0F9j6b-1)

## ğŸ§± Paso 0: ConfiguraciÃ³n Inicial de AWS

Antes de empezar, asegurate de configurar correctamente tu entorno AWS:

**Video Explicativo**: [AWS Setup](https://drive.google.com/file/d/19cXLmVaiaNkhtlqN130TJ3S2vEd0XeDB/view)

### ğŸŒ CreaciÃ³n de Cuenta AWS

1. Ingresa a [AWS Sign-up](https://aws.amazon.com) y crea una cuenta nueva con tu correo electrÃ³nico.
2. Verifica tu direcciÃ³n email mediante el cÃ³digo enviado por AWS.
3. Selecciona tipo de cuenta: **Personal**.
4. Realiza la verificaciÃ³n con tarjeta de crÃ©dito/dÃ©bito.
5. Completa la verificaciÃ³n con nÃºmero de telÃ©fono (SMS).
6. Selecciona el plan **Basic Support** (gratuito).

### ğŸ’³ GestiÃ³n de Costos y Alertas  

1. Activa el acceso al panel de Billing desde IAM.
2. En Billing â†’ **Alert Preferences**, configura alertas vÃ­a email.
3. En Budgets, crea un presupuesto llamado **Zero spend budget** para monitorear gastos en tiempo real.

### ğŸ” CreaciÃ³n de Usuario IAM y CLI  

1. En IAM, crea un usuario administrador: `iamadmin` y habilita MFA (AutenticaciÃ³n Multifactor).
2. Guarda tu URL de login personalizada para IAM:
    ```
    https://<account_id>.signin.aws.amazon.com/console
    ```
3. Descarga e instala la [AWS CLI](https://aws.amazon.com/cli/).

### ğŸ–¥ï¸ ConfiguraciÃ³n Local con AWS CLI  

Configura tu usuario IAM localmente:

```bash
aws configure --profile iamadmin-general
```

Verifica configuraciÃ³n:

```bash
aws sts get-caller-identity --profile iamadmin-general
```

---

## â˜ï¸ Demo 1: Lanzando Tu Primera Instancia EC2

AprenderÃ¡s a desplegar y acceder a una mÃ¡quina virtual en la nube AWS.

### ğŸ”‘ Generar Key Pair

- Ve a EC2 â†’ Key Pair â†’ Crea una nueva clave y descÃ¡rgala (`tu_key.pem`).

### ğŸš¦ Crear Security Group

- Configura un Security Group que permita conexiones SSH (puerto 22) desde cualquier IP (`0.0.0.0/0`).

### ğŸš€ Lanzar Instancia EC2  

- Selecciona instancia tipo `t2.micro` con Ubuntu Linux.
- Usa la clave y Security Group creados anteriormente.

### ğŸ”Œ ConexiÃ³n SSH a EC2  

```bash
ssh -i "tu_key.pem" ubuntu@<EC2_PUBLIC_IP>
```

### ğŸ—‘ï¸ Destruir instancia

- Ve a EC2 â†’ Instancias â†’ Selecciona la instancia y destrÃºyela.
- Elimina el Security Group creado.
- Elimina la Key Pair.


### ğŸŒ³ AutomaciÃ³n con Terraform  

Automatiza estos pasos con Terraform:

```bash
terraform init
terraform plan -var="ssh_key_name=tu_ssh_key_name"
terraform apply -var="ssh_key_name=tu_ssh_key_name"
terraform destroy -var="ssh_key_name=tu_ssh_key_name"
```

ğŸ“ **Assets:** disponibles en carpeta [**01-demo**](https://github.com/ingenieria-del-software-2/cloudcomputing-demo/tree/main/01-demo)

---

## ğŸ—ƒï¸ Demo 2: GestiÃ³n de Acceso con IAM y S3

Control de acceso y polÃ­ticas IAM avanzadas con CloudFormation.

### ğŸ“¦ Despliegue CloudFormation Stack  

La plantilla crea:

- Dos buckets S3 (`animals` y `dogs`).
- Usuario IAM: `Messi`.
- PolÃ­tica IAM: acceso a todo excepto al bucket `dogs`.

### ğŸ“¤ Uso del Bucket S3  

- En `animals`: sube imÃ¡genes de gatos.
- En `dogs`: sube imÃ¡genes de perros.

### ğŸ›¡ï¸ VerificaciÃ³n Acceso IAM  

- Inicia sesiÃ³n con usuario Messi en ventana incÃ³gnita.
- Intenta acceder al bucket `dogs`: **el acceso debe ser denegado**.

### ğŸ”§ ModificaciÃ³n de la PolÃ­tica  

- Elimina polÃ­tica actual.
- Aplica polÃ­tica que permita **Ãºnicamente acceso al bucket `dogs`**.

### ğŸ—‘ï¸ Limpieza  

- Elimina archivos S3.
- Desasocia polÃ­tica IAM del usuario Messi.
- Destruye stack CloudFormation.

ğŸ“ **Assets:** disponibles en carpeta [**2-demo**](https://github.com/ingenieria-del-software-2/cloudcomputing-demo/tree/main/01-demo)

---

## ğŸ”„ Demo 3: CI/CD con EC2, Docker y Traefik

Esta demo estÃ¡ completamente automatizada con **Terraform**. En el bloque `user_data` (metadata de EC2) se incluye:

- InstalaciÃ³n de Docker y Docker Compose.
- CreaciÃ³n de red compartida `traefik-shared`.
- Despliegue Ãºnico de Traefik y Jaeger con Compose.

Cada microservicio se encuentra en su propio repositorio y tiene su propio archivo `docker-compose.yaml` que referencia la variable `<MICROSERVICE_NAME>_VERSION`, la cual es inyectada automÃ¡ticamente en el deploy desde GitHub Actions. Ejemplos: [kiosko-fiuba-product-catalog](https://github.com/ingenieria-del-software-2/kiosko-fiuba-product-catalog/blob/main/docker-compose.yml) y [kiosko-fiuba-shopping-experience](https://github.com/ingenieria-del-software-2/kiosko-fiuba-shopping-experience/blob/main/docker-compose.yml)

AdemÃ¡s, esta demo cuenta con una **versiÃ³n opcional para GCP**, que replica el mismo pipeline y despliegue utilizando una VM en Google Cloud y `gcloud CLI` en lugar de AWS CLI.

ğŸ“ Los assets para esta demo estÃ¡n en la carpeta [**03-demo**](https://github.com/ingenieria-del-software-2/cloudcomputing-demo/tree/main/03-demo)

### Diagrama de arquitectura de los servicios (Traefik y Microservicios)

```mermaid
graph TD
  subgraph Accesos
    ext[cliente externo - fuera de la VM]
    local[localhost - cliente local]
    ext -->|PathPrefix /product-catalog| T
    local -->|product_catalog.localhost| T
    ext -->|PathPrefix /service-b| T
    local -->|service_b.localhost| T
  end

  subgraph RedInterna
    direction LR
    MS2[container service-b - port 8000]
    C[container api - port 8000]
    MS2 -->|llama a| C
  end

  subgraph Traefik
    T[traefik]
    T -->|labels| R1[router product_catalog]
    R1 --> S1[service product_catalog]
    S1 --> C

    T -->|labels| R2[router service_b]
    R2 --> S2[service service_b]
    S2 --> MS2
  end
```

### Pipeline CI/CD

```mermaid
graph TD
  A[GitHub Push a main] --> B[Build Job]
  B --> C[Login a Container Registry -ECR o Artifact]
  C --> D[Build de imagen Docker]
  D --> E[Push con tag github.sha]
  E --> F[Set output image uri]

  A --> G[Deploy Job]
  F --> G
  G --> H[SSH a VM - EC2 o GCP]
  H --> I[Copiar docker-compose.yaml vÃ­a SCP]
  I --> J[export MICROSERVICE_NAME_VERSION=$image]
  J --> K[docker compose pull && up -d]

  subgraph Infraestructura inicial
    L[VM creada con Terraform]
    M[Metadata instala Docker, Traefik y red traefik-shared]
  end

  L --> H
```

## ğŸ” Secrets utilizados en el pipeline (GitHub Actions)

### **ğŸ”¸ AWS**

| Secreto                  | DescripciÃ³n                                                                  |
|--------------------------|------------------------------------------------------------------------------|
| `AWS_ACCESS_KEY_ID`      | Access key del usuario IAM `pipeline-user`                                   |
| `AWS_SECRET_ACCESS_KEY`  | Secret key del usuario IAM `pipeline-user`                                   |
| `AWS_ACCOUNT_ID`         | ID de la cuenta AWS (solo nÃºmeros, sin espacios ni guiones)                  |
| `EC2_HOST`               | DirecciÃ³n IP o DNS pÃºblico de la instancia EC2                               |
| `EC2_SSH_KEY`            | Clave privada del Key Pair utilizado por EC2 (en texto plano, sin passphrase) |

> ğŸ” El `ECR_URI` ahora se construye automÃ¡ticamente en el pipeline como:  
> `${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com`

### **ğŸ”¹ GCP**

| Secreto                   | DescripciÃ³n                                                                 |
|---------------------------|-----------------------------------------------------------------------------|
| `GCP_SERVICE_ACCOUNT_KEY` | JSON con credenciales del Service Account `pipeline-user`                   |
| `GCP_VM_HOST`             | DirecciÃ³n IP o DNS pÃºblico de la instancia GCP                              |
| `GCP_SSH_KEY`             | Clave privada utilizada para conectar vÃ­a SSH (sin passphrase, en texto plano) |
| `GCP_PROJECT_ID`          | ID del proyecto de GCP                                                      |
| `REGION`                  | RegiÃ³n de Artifact Registry en GCP (ejemplo: `us-central1`)                 |


### ğŸ” Permisos del Pipeline

Tanto en AWS como en GCP, se automatiza la creaciÃ³n de los permisos necesarios usando **Terraform**, con excepciÃ³n de las credenciales secretas necesarias para CI/CD (las access keys en AWS y las keys de service account en GCP), que **deben generarse manualmente**.

#### AWS - IAM User para ECR

```bash
# Crear usuario IAM
aws iam create-user --user-name pipeline-user

# Asignar permisos para acceso total a ECR
aws iam attach-user-policy \
  --user-name pipeline-user \
  --policy-arn arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryPowerUser

# (Manual) Crear una access key (guÃ¡rdala en GitHub Secrets)
aws iam create-access-key --user-name pipeline-user
```

Este flujo estarÃ¡ definido en Terraform, excepto la generaciÃ³n de la access key, que debe guardarse como secreto en GitHub Actions (`AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`).

#### GCP - Service Account para Artifact Registry

```bash
# Crear Service Account
gcloud iam service-accounts create pipeline-user --display-name "Pipeline User"

# Obtener el ID del proyecto
PROJECT_ID=$(gcloud config get-value project)

# Asignar el rol de escritor en Artifact Registry
gcloud projects add-iam-policy-binding $PROJECT_ID \
  --member="serviceAccount:pipeline-user@$PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/artifactregistry.writer"

# (Manual) Crear una key JSON (guÃ¡rdala en GitHub Secrets)
gcloud iam service-accounts keys create ./pipeline_credentials.json \
  --iam-account=pipeline-user@$PROJECT_ID.iam.gserviceaccount.com
```

La infraestructura de GCP (VM, red, permisos) estÃ¡ escrita en Terraform, excepto la generaciÃ³n del archivo `pipeline_credentials.json`, que debe subirse como secreto a GitHub Actions (`GCP_SERVICE_ACCOUNT_KEY`).

---

## ğŸ§¹ Limpieza Final  

Luego de la clase:

- Borra instancias EC2 y Key Pair usados.
- VacÃ­a y elimina buckets S3.
- Usa Terraform para destruir todos los recursos creados:

```bash
terraform destroy
```

---

## ğŸ§  Buenas PrÃ¡cticas  

- Usa siempre perfiles IAM limitados para mejorar seguridad.
- Habilita MFA en cuenta root AWS.
- Usa siempre `terraform plan` antes de aplicar cambios.
- Revisa siempre logs detallados ante errores (CloudFormation, Terraform).
- Para practicar IAM, usa mÃºltiples ventanas o sesiones separadas.

---

ğŸ“Œ **Â¡Buena suerte y a disfrutar la clase!**
