# ğŸš€ Cloud Computing Demo - IngenierÃ­a del Software II  

Este repositorio contiene instrucciones detalladas y recursos utilizados durante la clase prÃ¡ctica de Cloud Computing. AquÃ­ aprenderÃ¡s desde los primeros pasos bÃ¡sicos hasta prÃ¡cticas avanzadas con infraestructura como cÃ³digo y pipelines CI/CD usando AWS y GCP.

**Diapos**: [Cloud Computing Slides](https://www.figma.com/deck/yJpxpjW6aJOpFBCW7TE1xW/ISW2---Cloud-Computing?node-id=1-660&t=ep8V4cm1Nw0F9j6b-1)

## ğŸ§± Paso 0: ConfiguraciÃ³n Inicial de AWS

Antes de empezar, asegurate de configurar correctamente tu entorno AWS:

**Video Explicativo**: [AWS Setup](https://drive.google.com/file/d/19cXLmVaiaNkhtlqN130TJ3S2vEd0XeDB/view)

### ğŸŒ CreaciÃ³n de Cuenta AWS

1. Ingresa a [AWS Sign-up](https://aws.amazon.com) y crea una cuenta nueva con tu correo electrÃ³nico.
2. Verifica tu direcciÃ³n email mediante el cÃ³digo enviado por AWS.
3. Selecciona tipo de cuenta: **Personal**.
4. Realiza la verificaciÃ³n con tarjeta de crÃ©dito/dÃ©bito.
5. Completa la verificaciÃ³n con nÃºmero de telÃ©fono (SMS).
6. Selecciona el plan **Basic Support** (gratuito).

### ğŸ’³ GestiÃ³n de Costos y Alertas  

1. Activa el acceso al panel de Billing desde IAM.
2. En Billing â†’ **Alert Preferences**, configura alertas vÃ­a email.
3. En Budgets, crea un presupuesto llamado **Zero spend budget** para monitorear gastos en tiempo real.

### ğŸ” CreaciÃ³n de Usuario IAM y CLI  

1. En IAM, crea un usuario administrador: `iamadmin` y habilita MFA (AutenticaciÃ³n Multifactor).
2. Guarda tu URL de login personalizada para IAM:
    ```
    https://<account_id>.signin.aws.amazon.com/console
    ```
3. Descarga e instala la [AWS CLI](https://aws.amazon.com/cli/).

### ğŸ–¥ï¸ ConfiguraciÃ³n Local con AWS CLI  

Configura tu usuario IAM localmente:

```bash
aws configure --profile iamadmin-general
```

Verifica configuraciÃ³n:

```bash
aws sts get-caller-identity --profile iamadmin-general
```

---

## â˜ï¸ Demo 1: Lanzando Tu Primera Instancia EC2

AprenderÃ¡s a desplegar y acceder a una mÃ¡quina virtual en la nube AWS.

### ğŸ”‘ Generar Key Pair

- Ve a EC2 â†’ Key Pair â†’ Crea una nueva clave y descÃ¡rgala (`tu_key.pem`).

### ğŸš¦ Crear Security Group

- Configura un Security Group que permita conexiones SSH (puerto 22) desde cualquier IP (`0.0.0.0/0`).

### ğŸš€ Lanzar Instancia EC2  

- Selecciona instancia tipo `t2.micro` con Ubuntu Linux.
- Usa la clave y Security Group creados anteriormente.

### ğŸ”Œ ConexiÃ³n SSH a EC2  

```bash
ssh -i "tu_key.pem" ubuntu@<EC2_PUBLIC_IP>
```

### ğŸ—‘ï¸ Destruir instancia

- Ve a EC2 â†’ Instancias â†’ Selecciona la instancia y destrÃºyela.
- Elimina el Security Group creado.
- Elimina la Key Pair.


### ğŸŒ³ AutomaciÃ³n con Terraform  

Automatiza estos pasos con Terraform:

```bash
terraform init
terraform plan -var="ssh_key_name=tu_ssh_key_name"
terraform apply -var="ssh_key_name=tu_ssh_key_name"
terraform destroy -var="ssh_key_name=tu_ssh_key_name"
```

ğŸ“ **Assets:** disponibles en carpeta [**01-demo**](https://github.com/ingenieria-del-software-2/cloudcomputing-demo/tree/main/01-demo)

---

## ğŸ—ƒï¸ Demo 2: GestiÃ³n de Acceso con IAM y S3

Control de acceso y polÃ­ticas IAM avanzadas con CloudFormation.

### ğŸ“¦ Despliegue CloudFormation Stack  

La plantilla crea:

- Dos buckets S3 (`animals` y `dogs`).
- Usuario IAM: `Messi`.
- PolÃ­tica IAM: acceso a todo excepto al bucket `dogs`.

### ğŸ“¤ Uso del Bucket S3  

- En `animals`: sube imÃ¡genes de gatos.
- En `dogs`: sube imÃ¡genes de perros.

### ğŸ›¡ï¸ VerificaciÃ³n Acceso IAM  

- Inicia sesiÃ³n con usuario Messi en ventana incÃ³gnita.
- Intenta acceder al bucket `dogs`: **el acceso debe ser denegado**.

### ğŸ”§ ModificaciÃ³n de la PolÃ­tica  

- Elimina polÃ­tica actual.
- Aplica polÃ­tica que permita **Ãºnicamente acceso al bucket `dogs`**.

### ğŸ—‘ï¸ Limpieza  

- Elimina archivos S3.
- Desasocia polÃ­tica IAM del usuario Messi.
- Destruye stack CloudFormation.

ğŸ“ **Assets:** disponibles en carpeta [**2-demo**](https://github.com/ingenieria-del-software-2/cloudcomputing-demo/tree/main/01-demo)

---

## ğŸ”„ Demo 3: CI/CD con EC2, Docker y Traefik

Esta demo estÃ¡ completamente automatizada con **Terraform**. En el bloque `user_data` (metadata de EC2) se incluye:

- InstalaciÃ³n de Docker y Docker Compose.
- CreaciÃ³n de red compartida `traefik-shared`.
- Despliegue Ãºnico de Traefik y Jaeger con Compose.

Cada microservicio se encuentra en su propio repositorio y tiene su propio archivo `compose.prod.yaml` que referencia la variable `<MICROSERVICE_NAME>_VERSION`, la cual es inyectada automÃ¡ticamente en el deploy desde GitHub Actions. Ejemplos: [kiosko-fiuba-product-catalog](https://github.com/ingenieria-del-software-2/kiosko-fiuba-product-catalog/blob/main/compose.prod.yml) y [kiosko-fiuba-shopping-experience](https://github.com/ingenieria-del-software-2/kiosko-fiuba-shopping-experience/blob/main/compose.prod.yml). Es importante que este compose, tenga la red externa de Traefik configurada como `traefik-shared` y a su vez todas las variables de entorno y labels necesarias para el despliegue.

AdemÃ¡s, esta demo cuenta con una **versiÃ³n opcional para GCP**, que replica el mismo pipeline y despliegue utilizando una VM en Google Cloud y `gcloud CLI` en lugar de AWS CLI.

ğŸ“ Los assets para esta demo estÃ¡n en la carpeta [**03-demo**](https://github.com/ingenieria-del-software-2/cloudcomputing-demo/tree/main/03-demo)

### Diagrama de arquitectura de los servicios (Traefik y Microservicios)

```mermaid
graph TD
  subgraph Accesos
    ext[cliente externo - fuera de la VM]
    local[localhost - cliente local]
    ext -->|PathPrefix /product-catalog| T
    local -->|product_catalog.localhost| T
    ext -->|PathPrefix /service-b| T
    local -->|service_b.localhost| T
  end

  subgraph RedInterna
    direction LR
    MS2[container service-b - port 8000]
    C[container api - port 8000]
    MS2 -->|llama a| C
  end

  subgraph Traefik
    T[traefik]
    T -->|labels| R1[router product_catalog]
    R1 --> S1[service product_catalog]
    S1 --> C

    T -->|labels| R2[router service_b]
    R2 --> S2[service service_b]
    S2 --> MS2
  end
```

### Pipeline CI/CD

```mermaid
graph TD
  A[GitHub Push a main] --> B[Build Job]
  B --> C[Login a Container Registry -ECR o Artifact]
  C --> D[Build de imagen Docker]
  D --> E[Push con tag github.sha]
  E --> F[Set output image uri]

  A --> G[Deploy Job]
  F --> G
  G --> H[SSH a VM - EC2 o GCP]
  H --> I[Copiar docker-compose.yaml vÃ­a SCP]
  I --> J[export MICROSERVICE_NAME_VERSION=$image]
  J --> K[docker compose pull && up -d]

  subgraph Infraestructura inicial
    L[VM creada con Terraform]
    M[Metadata instala Docker, Traefik y red traefik-shared]
  end

  L --> H
```

---

## ğŸ”‘ Secrets utilizados en el pipeline (GitHub Actions)

Estos secretos deben configurarse en la secciÃ³n **Settings > Secrets and variables > Actions** del repositorio de GitHub.

### ğŸ”¸ **AWS**

| Secreto                  | DescripciÃ³n                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| `AWS_ACCESS_KEY_ID`      | Access key del usuario IAM `pipeline-user`                                  |
| `AWS_SECRET_ACCESS_KEY`  | Secret key del usuario IAM `pipeline-user`                                  |
| `AWS_ACCOUNT_ID`         | ID numÃ©rico de tu cuenta AWS (sin espacios ni guiones)                      |
| `EC2_HOST`               | DirecciÃ³n IP o DNS pÃºblico de la instancia EC2                              |
| `EC2_SSH_KEY`            | Clave privada del Key Pair utilizada por EC2 (formato texto plano, sin passphrase) |

> ğŸ§  El URI del repositorio ECR se construye automÃ¡ticamente en el pipeline como:  
> `\${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com`

### ğŸ”¹ **GCP**

| Secreto                   | DescripciÃ³n                                                                   |
|---------------------------|-------------------------------------------------------------------------------|
| `GCP_PROJECT_ID`          | ID del proyecto de GCP                                                        |
| `GCP_SERVICE_ACCOUNT_KEY` | JSON con credenciales del Service Account `pipeline-user`                     |
| `GCP_USERNAME`            | Nombre de usuario para SSH (usualmente es el username de la cuenta de Google) |
| `GCP_VM_HOST`             | DirecciÃ³n IP o DNS pÃºblico de la instancia VM de GCP                          |
| `GCP_SSH_KEY`             | Clave privada para conexiÃ³n SSH (sin passphrase, en texto plano)              |

> ğŸ§  El URI de la imagen en Artifact Registry se construye asÃ­:  
> `\${{ secrets.REGION }}-docker.pkg.dev/\${{ secrets.GCP_PROJECT_ID }}/<repo>/<microservicio>:<tag>`

## âš ï¸ APIs de Google Cloud requeridas

Para que el pipeline de despliegue en GCP funcione correctamente, debes habilitar las siguientes APIs en tu proyecto de Google Cloud:

- **Compute Engine API** - Para el despliegue y gestiÃ³n de VMs
- **IAM Credentials API** - Para la autenticaciÃ³n y autorizaciÃ³n del Service Account

Puedes habilitar estas APIs desde la consola de Google Cloud o usando el siguiente comando:

```bash
gcloud services enable compute.googleapis.com iamcredentials.googleapis.com
```

## ğŸ” Permisos del Pipeline

Tanto en AWS como en GCP, Terraform automatiza la creaciÃ³n de los roles, permisos y cuentas necesarios para el pipeline CI/CD. Sin embargo, las credenciales secretas (access keys y service account keys) deben obtenerse despuÃ©s del despliegue para configurarlas en GitHub Actions.

#### AWS - IAM User para ECR

Terraform crea el usuario IAM `pipeline-user` con permisos para publicar imÃ¡genes en ECR. Para obtener sus credenciales:

```bash
# âš ï¸ Primero, edita el archivo terraform.tfvars para configurar tus variables (ssh_key_name, etc.)

# Aplica la configuraciÃ³n Terraform si no lo has hecho
terraform apply

# ObtÃ©n las credenciales (generadas automÃ¡ticamente)
terraform output -raw AWS_ACCESS_KEY_ID
terraform output -raw AWS_SECRET_ACCESS_KEY
```

**ConfiguraciÃ³n en GitHub Actions**:
Usa las credenciales obtenidas para configurar los secretos en GitHub Actions segÃºn la tabla de AWS mostrada anteriormente.

**Uso en workflow**:
```yaml
- name: Configure AWS credentials
  uses: aws-actions/configure-aws-credentials@v1
  with:
    aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
    aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    aws-region: us-east-1
```

#### GCP - Service Account para Artifact Registry

Terraform crea la cuenta de servicio `pipeline-user` con permisos para publicar en Artifact Registry. Para obtener su clave:

```bash
# âš ï¸ Primero, edita el archivo terraform.tfvars para configurar tus variables (project_id, etc.)

# Aplica la configuraciÃ³n Terraform si no lo has hecho
terraform apply

# Extrae la clave JSON (codificada en base64)
terraform output -raw GCP_SERVICE_ACCOUNT_KEY_ENCODED | base64 --decode > gcp_service_account_key.json
```

**ConfiguraciÃ³n en GitHub Actions**:
Usa el archivo `gcp_service_account_key.json` generado para configurar el secreto `GCP_SERVICE_ACCOUNT_KEY` en GitHub Actions.

**Uso en workflow**:
```yaml
- name: Auth to Google Cloud
  uses: google-github-actions/auth@v1
  with:
    credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
```

**Limpieza de seguridad**: DespuÃ©s de configurar los secretos, elimina las credenciales locales:
```bash
rm gcp_service_account_key.json  # Para GCP
```

## ğŸ§¹ Limpieza Final  

Luego de la clase:

- Borra instancias EC2 y Key Pair usados.
- VacÃ­a y elimina buckets S3.
- Usa Terraform para destruir todos los recursos creados:

```bash
terraform destroy
```

---

## ğŸ§  Buenas PrÃ¡cticas  

- Usa siempre perfiles IAM limitados para mejorar seguridad.
- Habilita MFA en cuenta root AWS.
- Usa siempre `terraform plan` antes de aplicar cambios.
- Revisa siempre logs detallados ante errores (CloudFormation, Terraform).
- Para practicar IAM, usa mÃºltiples ventanas o sesiones separadas.

---

ğŸ“Œ **Â¡Buena suerte y a disfrutar la clase!**
